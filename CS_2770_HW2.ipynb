{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS 2770 HW2",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMszWGwbj/0ELmx9QCRkEeq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maxwellreynolds/ComputerVision_Notebooks/blob/master/CS_2770_HW2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQ00v2WRc-cW"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2v65JarO-24b"
      },
      "source": [
        "# Part A: Loading and Using a Pretrained Network as a Feature Extractor "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "530YZHTIdBvR",
        "outputId": "428dd815-3ef6-4ea0-cfe9-e2e52fbbe030"
      },
      "source": [
        "print(\"GPU Model: %s\" % torch.cuda.get_device_name(0))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU Model: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUjiZYYAdGwa"
      },
      "source": [
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "      transforms.Resize((224,224)),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "  ]),\n",
        "  'val': transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "  ]),\n",
        "  'test': transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "  ]),\n",
        "}"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaOiBRa4dhee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2098aa43-fa57-481e-e53a-175ab4a232a9"
      },
      "source": [
        "data_dir = 'hw2_data'\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x])\n",
        "  for x in ['train', 'val', 'test']}\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=8, shuffle=True, num_workers=4)\n",
        "  for x in ['train', 'val' , 'test']}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val', 'test']}\n",
        "class_names = image_datasets['train'].classes\n",
        "\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nf2Q6xlciiQN"
      },
      "source": [
        "class VGG16_Feature_Extraction(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(VGG16_Feature_Extraction, self).__init__()\n",
        "    VGG16_Pretrained = models.vgg16(pretrained=True)\n",
        "    self.features = VGG16_Pretrained.features\n",
        "    self.avgpool = VGG16_Pretrained.avgpool\n",
        "    self.feature_extractor = nn.Sequential(*[VGG16_Pretrained.classifier[i] for i in range(6)])\n",
        "  def forward(self, x):\n",
        "    x = self.features(x)\n",
        "    x = self.avgpool(x)\n",
        "    x = torch.flatten(x, 1)\n",
        "    x = self.feature_extractor(x)\n",
        "    return x\n",
        "\n",
        "\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHI6ree2in6d"
      },
      "source": [
        "# models.vgg16(pretrained=True).classifier"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KbzqDFwis7N"
      },
      "source": [
        "model=VGG16_Feature_Extraction()\n",
        "device = 'cuda:0'\n",
        "model=model.to(device)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZ7iwceKit28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16051e8c-7f4e-4a59-ecb1-1f44aa2c4899"
      },
      "source": [
        "image_features = {}\n",
        "image_labels = {}\n",
        "for phase in ['train', 'test']:\n",
        "  for inputs, labels in dataloaders[phase]:\n",
        "    inputs=inputs.to(device)\n",
        "    model_prediction = model(inputs)\n",
        "    model_prediction_numpy=model_prediction.cpu().detach().numpy()\n",
        "    if phase not in image_features:\n",
        "      image_features[phase]=model_prediction_numpy\n",
        "      image_labels[phase]=labels.numpy()\n",
        "    else:\n",
        "      image_features[phase] = np.concatenate((image_features[phase], model_prediction_numpy), axis=0)\n",
        "      image_labels[phase] = np.concatenate((image_labels[phase], labels.numpy()), axis=0)\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUY7hneTxk0N"
      },
      "source": [
        "#Transform data to mean 0 std 1\n",
        "scaler=StandardScaler().fit(image_features['train'])\n",
        "train_features_scaled=scaler.transform(image_features['train'])\n",
        "scaler=StandardScaler().fit(image_features['test'])\n",
        "test_features_scaled=scaler.transform(image_features['test'])\n",
        "\n"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YsxH9EdryNEX",
        "outputId": "834e427a-01d0-46e0-9919-df72d4176a44"
      },
      "source": [
        "# clf = make_pipeline(StandardScaler(), svm.LinearSVC(random_state=0, tol=1e-5))\n",
        "# clf.fit(train_features_scaled, image_labels['train'])\n",
        "# y_pred=clf.predict(train_features_scaled)\n",
        "# y_true=image_labels['train']\n",
        "# print(\"Sanity check: \",accuracy_score(y_true,y_pred), \" train accuracy\")\n",
        "# y_pred=clf.predict(test_features_scaled)\n",
        "# y_true=image_labels['test']\n",
        "# print(\"Test accuracy: \",accuracy_score(y_true,y_pred))\n"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sanity check:  1.0  train accuracy\n",
            "Test accuracy:  0.5168067226890757\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32JA0BQtyZvW"
      },
      "source": [
        "model=svm.LinearSVC(random_state=0, tol=1e-5).fit(train_features_scaled, image_labels['train'])"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9DL0s-24AQn",
        "outputId": "a6bbadba-072d-4694-9ccf-33de7a593e61"
      },
      "source": [
        "y_pred=model.predict(train_features_scaled)\n",
        "y_true=image_labels['train']\n",
        "print(\"Sanity check: \",accuracy_score(y_true,y_pred), \" train accuracy\")\n",
        "y_pred=model.predict(test_features_scaled)\n",
        "y_true=image_labels['test']\n",
        "print(\"Test accuracy: \",accuracy_score(y_true,y_pred))"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sanity check:  1.0  train accuracy\n",
            "Test accuracy:  0.5168067226890757\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8R_336j4qfY",
        "outputId": "39186100-daa7-4485-c8c4-7da41de89b3d"
      },
      "source": [
        "confusion_matrix(y_true, y_pred)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[19,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  2,  0,  0,  0,  1,\n",
              "         0,  0,  1,  1],\n",
              "       [ 0, 14,  0,  1,  1,  0,  2,  0,  0,  1,  0,  0,  0,  3,  1,  0,\n",
              "         0,  0,  0,  2],\n",
              "       [ 0,  0, 19,  1,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  1,\n",
              "         0,  0,  0,  2],\n",
              "       [ 0,  1,  0, 20,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  1,  0,\n",
              "         0,  1,  0,  1],\n",
              "       [ 0,  1,  0,  1,  5,  0,  0,  0,  2,  0,  6,  0,  0,  0,  1,  3,\n",
              "         0,  1,  0,  5],\n",
              "       [ 0,  0,  0,  0,  0, 16,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  1,  2,  0],\n",
              "       [ 2,  4,  0,  2,  0,  1,  9,  0,  0,  0,  1,  1,  0,  2,  0,  1,\n",
              "         0,  0,  1,  1],\n",
              "       [ 0,  0,  0,  0,  1,  0,  0, 17,  0,  0,  0,  3,  0,  0,  0,  1,\n",
              "         0,  3,  0,  0],\n",
              "       [ 0,  0,  1,  0,  3,  0,  0,  0,  5,  0,  7,  0,  1,  0,  1,  3,\n",
              "         0,  1,  0,  3],\n",
              "       [ 0,  0,  0,  1,  0,  0,  1,  0,  1,  5,  0,  2,  2,  0,  2,  0,\n",
              "         1,  0,  0,  0],\n",
              "       [ 0,  1,  0,  0,  6,  0,  1,  2,  1,  1,  8,  0,  0,  1,  2,  1,\n",
              "         0,  1,  0,  0],\n",
              "       [ 0,  0,  1,  1,  1,  0,  0,  2,  1,  0,  2,  9,  1,  0,  1,  1,\n",
              "         0,  4,  0,  1],\n",
              "       [ 0,  1,  0,  0,  1,  0,  2,  0,  0,  1,  0,  1, 12,  0,  1,  0,\n",
              "         3,  1,  0,  0],\n",
              "       [ 0,  2,  0,  0,  0,  0,  1,  0,  1,  0,  0,  0,  0, 18,  2,  1,\n",
              "         0,  0,  0,  0],\n",
              "       [ 2,  0,  0,  0,  2,  1,  2,  0,  2,  1,  2,  2,  1,  0,  6,  1,\n",
              "         0,  1,  0,  2],\n",
              "       [ 0,  2,  0,  0,  0,  1,  1,  0,  3,  0,  2,  1,  0,  0,  2,  7,\n",
              "         0,  2,  1,  3],\n",
              "       [ 0,  0,  1,  0,  1,  0,  1,  1,  1,  0,  1,  1,  2,  0,  2,  0,\n",
              "         6,  0,  0,  0],\n",
              "       [ 0,  0,  0,  0,  0,  0,  1,  1,  5,  0,  1,  0,  0,  0,  2,  1,\n",
              "         0, 11,  0,  3],\n",
              "       [ 0,  0,  0,  0,  1,  2,  0,  0,  0,  0,  0,  0,  0,  0,  1,  0,\n",
              "         0,  0, 21,  0],\n",
              "       [ 0,  0,  0,  0,  0,  1,  0,  0,  1,  0,  1,  0,  0,  0,  2,  0,\n",
              "         0,  1,  0, 19]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsKQxhjC4rN0",
        "outputId": "f9287f6f-dece-43bf-bb9f-b36726b73b88"
      },
      "source": [
        "conf_mat=confusion_matrix(y_true, y_pred)\n",
        "for i in range(conf_mat.shape[0]):\n",
        "  class_accuracy=(conf_mat[i][i])/(conf_mat[i].sum())\n",
        "  print(class_names[i], class_accuracy)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "aeroplane 0.76\n",
            "bicycle 0.56\n",
            "bird 0.76\n",
            "boat 0.8\n",
            "bottle 0.2\n",
            "bus 0.7619047619047619\n",
            "car 0.36\n",
            "cat 0.68\n",
            "chair 0.2\n",
            "cow 0.3333333333333333\n",
            "diningtable 0.32\n",
            "dog 0.36\n",
            "horse 0.5217391304347826\n",
            "motorbike 0.72\n",
            "person 0.24\n",
            "pottedplant 0.28\n",
            "sheep 0.35294117647058826\n",
            "sofa 0.44\n",
            "train 0.84\n",
            "tvmonitor 0.76\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ng_L_YN28iha"
      },
      "source": [
        "The model was able to generalize to some degree. Although the accuracy was only around 51%, this is still significantly better than random chance given that there are 20 classes. Accuracy was highest for train, tvmonitor, aeroplane, and bus while lowest for bottle, chair, person. One odd miscslassification was water bottles classified more often as dining tables than water bottles."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzRGtADc-TYK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXlrKz6z_AE2"
      },
      "source": [
        "# Part B: Train and Test the CNN on Our Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gS5J6DXh-_vg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}